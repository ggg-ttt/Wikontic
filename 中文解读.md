# Wikontic 项目使用指南

## 项目概述

**Wikontic** 是一个基于大语言模型(LLM)和Wikidata的本体感知知识图谱构建工具。它能够从原始文本中提取三元组，并通过本体对齐、模式验证和实体去重等步骤，构建出与Wikidata对齐的紧凑、语义连贯的知识图谱。

## 项目文件结构

```
Wikontic/
├── analysis/                          # 结果分析notebooks
├── create_ontological_triplets_db.py  # 创建本体三元组数据库
├── create_triplets_db.py             # 创建普通三元组数据库（不使用本体）
├── create_wikidata_ontology_db.py    # 创建Wikidata本体数据库
├── datasets/                         # 数据集文件夹
├── Dockerfile                        # Docker容器构建文件
├── inference_and_eval/               # 推理和评估脚本
├── media/                           # 媒体文件（图片等）
├── pages/                           # Web服务页面
├── preprocessing/                    # 预处理文件
├── README.md                        # 项目说明文档
├── requirements.txt                 # Python依赖包
├── setup_db.sh                      # 数据库初始化脚本
├── utils/                           # 工具模块
│   ├── openai_utils.py             # OpenAI LLM三元组提取
│   ├── structured_inference_with_db.py  # 结构化推理（使用本体）
│   ├── structured_aligner.py       # 结构化对齐器（使用本体）
│   ├── inference_with_db.py        # 普通推理（不使用本体）
│   ├── dynamic_aligner.py          # 动态对齐器（不使用本体）
│   ├── ontology_mappings/          # 本体映射文件
│   └── open_source_llm_utils.py   # 开源LLM工具
└── Wikontic.py                     # 主Web服务入口
```

## 核心功能模块

### 1. 数据库初始化脚本

- **[create_wikidata_ontology_db.py](create_wikidata_ontology_db.py)**: 创建Wikidata本体数据库，包括实体类型、属性、约束规则等
- **[create_ontological_triplets_db.py](create_ontological_triplets_db.py)**: 创建支持本体对齐的三元组数据库
- **[create_triplets_db.py](create_triplets_db.py)**: 创建普通三元组数据库（不使用本体约束）

### 2. 知识图谱构建工具

#### 使用本体约束（推荐）：
- **[utils/structured_inference_with_db.py](utils/structured_inference_with_db.py)**: `StructuredInferenceWithDB`类，提供三元组提取和问答功能
- **[utils/structured_aligner.py](utils/structured_aligner.py)**: `Aligner`类，执行本体对齐和实体名称优化

#### 不使用本体约束：
- **[utils/inference_with_db.py](utils/inference_with_db.py)**: `InferenceWithDB`类，基础三元组提取和问答功能
- **[utils/dynamic_aligner.py](utils/dynamic_aligner.py)**: `Aligner`类，动态实体和关系名称优化

### 3. LLM接口
- **[utils/openai_utils.py](utils/openai_utils.py)**: OpenAI API的LLM三元组提取器
- **[utils/open_source_llm_utils.py](utils/open_source_llm_utils.py)**: 开源LLM支持

## 一次完整运行流程

### 1. 环境准备

```bash
# 安装Python依赖
pip install -r requirements.txt

# 启动MongoDB数据库
docker pull mongo
docker run --name text2kg_mongo -p 27018:27017 mongo:latest
```

### 2. 数据库初始化

#### 使用本体约束（推荐）：
```bash
# 运行数据库初始化脚本
./setup_db.sh
```

这个脚本会依次执行：
1. 启动MongoDB容器
2. 创建Wikidata本体数据库：`python3 create_wikidata_ontology_db.py`
3. 创建本体三元组数据库：`python3 create_ontological_triplets_db.py`

#### 不使用本体约束：
```bash
# 只运行普通数据库创建
python3 create_triplets_db.py
```

### 3. 启动Web服务

```bash
# 启动Streamlit Web服务
streamlit run Wikontic.py
```

Web服务将在浏览器中打开，提供知识图谱提取和可视化界面。

### 4. 编程方式使用

#### 使用本体约束构建知识图谱：

```python
from utils.structured_inference_with_db import StructuredInferenceWithDB
from utils.structured_aligner import Aligner

# 初始化推理器
inference = StructuredInferenceWithDB(
    mongo_uri="mongodb://localhost:27018/?directConnection=true",
    db_name="triplets_db"
)

# 提取三元组
text = "Apple Inc. was founded by Steve Jobs in Cupertino, California."
triplets = inference.extract_triplets(text, sample_id="sample_001")

# 本体对齐
aligner = Aligner(mongo_uri="mongodb://localhost:27018/?directConnection=true")
aligned_triplets = aligner.align_triplets(triplets)
```

#### 不使用本体约束：

```python
from utils.inference_with_db import InferenceWithDB
from utils.dynamic_aligner import Aligner

# 初始化推理器
inference = InferenceWithDB(
    mongo_uri="mongodb://localhost:27018/?directConnection=true",
    db_name="triplets_db"
)

# 提取三元组
text = "Apple Inc. was founded by Steve Jobs in Cupertino, California."
triplets = inference.extract_triplets(text, sample_id="sample_001")

# 动态对齐
aligner = Aligner(mongo_uri="mongodb://localhost:27018/?directConnection=true")
aligned_triplets = aligner.align_triplets(triplets)
```

## 关键配置

### MongoDB连接配置
- 默认URI：`mongodb://localhost:27018/?directConnection=true`
- 本体数据库名：`wikidata_ontology`
- 三元组数据库名：`triplets_db`

### 本体映射文件
位于 `utils/ontology_mappings/` 目录：
- `entity_type2label.json`: 实体类型标签映射
- `entity_type2aliases.json`: 实体类型别名映射
- `prop2label.json`: 属性标签映射
- `prop2constraints.json`: 属性约束规则
- `subj_constraint2prop.json`: 主语约束到属性的映射
- `obj_constraint2prop.json`: 宾语约束到属性的映射

## 运行模式选择

1. **本体模式（推荐）**：使用Wikidata本体约束，生成更准确、语义更规范的知识图谱
2. **非本体模式**：更灵活的三元组提取，不受预定义约束限制

选择模式主要通过使用不同的工具类来实现：
- 本体模式：使用`structured_*`系列工具类
- 非本体模式：使用`dynamic_*`或基础`inference_with_db`工具类

## 详细功能说明

### 数据库脚本详解

#### create_wikidata_ontology_db.py
这个脚本负责创建Wikidata本体数据库，包含以下功能：
- 加载Wikidata的实体类型、属性和约束规则
- 使用Contriever模型生成文本嵌入向量（768维）
- 创建MongoDB集合：entity_types、entity_type_aliases、properties、property_aliases
- 建立向量搜索索引，支持语义相似度检索

#### create_ontological_triplets_db.py
创建支持本体对齐的三元组数据库，包含以下集合：
- entity_aliases: 实体别名（带实体类型标签）
- property_aliases: 属性别名
- triplets: 最终三元组
- initial_triplets: 初始提取的三元组
- filtered_triplets: 过滤后的三元组
- ontology_filtered_triplets: 本体过滤后的三元组

#### create_triplets_db.py
创建简化的三元组数据库（不使用本体），适合快速原型开发。

### 核心工具类

#### StructuredInferenceWithDB
结构化推理类，主要功能：
- 基于LLM的三元组提取
- 支持多种LLM模型（OpenAI GPT、开源模型）
- 与MongoDB数据库集成
- 本体约束下的三元组验证

#### StructuredAligner
结构化对齐器，主要功能：
- 实体类型识别和对齐
- 属性名标准化
- 基于Wikidata本体的约束验证
- 实体去重和合并

#### InferenceWithDB & DynamicAligner
简化版本的工具类，不依赖预定义本体，提供更灵活的三元组提取和对齐功能。

## 技术架构

### 依赖技术栈
- **大语言模型**: OpenAI GPT系列、Hugging Face开源模型
- **向量数据库**: MongoDB Atlas Search (基于向量相似度检索)
- **嵌入模型**: Facebook Contriever (768维向量)
- **Web框架**: Streamlit
- **容器化**: Docker

### 数据流程
1. **文本输入** → LLM三元组提取 → 候选三元组
2. **候选三元组** → 本体对齐 → 类型标注和约束验证
3. **验证结果** → 实体去重 → 最终知识图谱
4. **知识图谱** → MongoDB存储 → 可视化展示

### 性能优化
- 使用GPU加速嵌入向量计算
- MongoDB索引优化查询性能
- 批量处理减少数据库操作
- 缓存机制避免重复计算

## 扩展和定制

### 添加新的本体映射
1. 在`utils/ontology_mappings/`目录添加新的JSON映射文件
2. 修改数据库初始化脚本加载新映射
3. 更新对齐器逻辑使用新约束

### 支持新的LLM模型
1. 在`utils/`目录下创建新的LLM工具文件
2. 实现标准化的三元组提取接口
3. 在配置中添加新模型选项

### 自定义评估指标
1. 在`inference_and_eval/`目录添加评估脚本
2. 实现新的评估函数
3. 集成到现有评估框架

## 常见问题和解决方案

### MongoDB连接问题
- 确保MongoDB容器正在运行：`docker ps`
- 检查端口映射：默认27018端口
- 验证连接URI格式正确

### GPU内存不足
- 修改CUDA设备设置：`os.environ["CUDA_VISIBLE_DEVICES"] = "0"`
- 使用较小的批次大小处理嵌入向量
- 考虑使用CPU模式（速度较慢）

### 本体映射加载失败
- 检查JSON文件格式是否正确
- 确认文件路径和权限
- 验证映射文件的完整性

## 总结

Wikontic是一个功能完整的知识图谱构建工具，支持从原始文本到结构化知识图谱的完整流程。项目的核心优势在于：

1. **本体感知**：与Wikidata对齐，确保生成知识图谱的语义规范性
2. **多模式支持**：既支持严格的本体约束模式，也支持灵活的非本体模式
3. **完整的工具链**：从数据预处理到最终可视化的全流程支持
4. **易于部署**：提供Docker支持和Web界面，便于使用和部署
5. **可扩展性**：模块化设计，支持自定义本体映射和LLM模型

通过遵循上述使用指南，用户可以快速搭建和使用Wikontic进行高质量知识图谱的构建工作。